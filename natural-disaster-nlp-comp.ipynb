{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ToDo:\n- preprocess text - lemmatization, remove stop words etc. \n- utlise preprocessed text\n- Try DistilBert https://www.kaggle.com/code/alexia/kerasnlp-starter-notebook-disaster-tweets\n- sklearn pipelines\n- cross validation\n","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn import feature_extraction, linear_model, model_selection, preprocessing\nfrom sklearn.model_selection import train_test_split, cross_validate\nfrom sklearn.metrics import f1_score, r2_score, accuracy_score\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.pipeline import Pipeline\nimport xgboost\nimport spacy","metadata":{"execution":{"iopub.status.busy":"2023-08-05T20:00:44.362029Z","iopub.execute_input":"2023-08-05T20:00:44.362625Z","iopub.status.idle":"2023-08-05T20:01:02.324272Z","shell.execute_reply.started":"2023-08-05T20:00:44.362588Z","shell.execute_reply":"2023-08-05T20:01:02.323129Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"nlp = spacy.load('en_core_web_sm')","metadata":{"execution":{"iopub.status.busy":"2023-08-05T20:01:02.326554Z","iopub.execute_input":"2023-08-05T20:01:02.327422Z","iopub.status.idle":"2023-08-05T20:01:03.566308Z","shell.execute_reply.started":"2023-08-05T20:01:02.327382Z","shell.execute_reply":"2023-08-05T20:01:03.565336Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-08-05T20:01:03.567801Z","iopub.execute_input":"2023-08-05T20:01:03.568820Z","iopub.status.idle":"2023-08-05T20:01:03.628775Z","shell.execute_reply.started":"2023-08-05T20:01:03.568778Z","shell.execute_reply":"2023-08-05T20:01:03.627868Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Preproc","metadata":{}},{"cell_type":"code","source":"# def lemmatize_remove_stop(doc):\n#     return (\" \".join([token.lemma_ for token in nlp(doc) if not token.is_stop])).strip().lower()","metadata":{"execution":{"iopub.status.busy":"2023-08-05T20:01:03.631795Z","iopub.execute_input":"2023-08-05T20:01:03.632165Z","iopub.status.idle":"2023-08-05T20:01:03.637285Z","shell.execute_reply.started":"2023-08-05T20:01:03.632131Z","shell.execute_reply":"2023-08-05T20:01:03.636229Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# train_df['text_preproc'] = train_df['text'].apply(lemmatize_remove_stop)\n# test_df['text_preproc'] = test_df['text'].apply(lemmatize_remove_stop)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T20:01:03.638484Z","iopub.execute_input":"2023-08-05T20:01:03.638782Z","iopub.status.idle":"2023-08-05T20:01:03.646716Z","shell.execute_reply.started":"2023-08-05T20:01:03.638757Z","shell.execute_reply":"2023-08-05T20:01:03.645731Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# X = train_df.set_index('id')\n# y = train_df.set_index('id')['target']\n\n# X_test = test_df.set_index('id')","metadata":{"execution":{"iopub.status.busy":"2023-08-05T20:01:03.648236Z","iopub.execute_input":"2023-08-05T20:01:03.648760Z","iopub.status.idle":"2023-08-05T20:01:03.656844Z","shell.execute_reply.started":"2023-08-05T20:01:03.648726Z","shell.execute_reply":"2023-08-05T20:01:03.655828Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# count_vectorizer = feature_extraction.text.CountVectorizer(max_features=5000)\n# X_bow_raw = count_vectorizer.fit_transform(X['text'])\n# X_test_bow_raw = count_vectorizer.transform(X_test['text'])\n\n# count_vectorizer2 = feature_extraction.text.CountVectorizer(max_features=5000)\n# X_bow = count_vectorizer2.fit_transform(X['text_preproc']);\n# X_test_bow = count_vectorizer2.transform(X_test['text_preproc']);","metadata":{"execution":{"iopub.status.busy":"2023-08-05T20:01:03.660068Z","iopub.execute_input":"2023-08-05T20:01:03.660363Z","iopub.status.idle":"2023-08-05T20:01:03.667524Z","shell.execute_reply.started":"2023-08-05T20:01:03.660332Z","shell.execute_reply":"2023-08-05T20:01:03.666532Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# tfidf_vectorizer = feature_extraction.text.TfidfVectorizer(max_features=5000)\n# X_tfidf_raw = tfidf_vectorizer.fit_transform(X['text'])\n# X_test_tfidf_raw = tfidf_vectorizer.transform(X_test['text'])\n\n# tfidf_vectorizer2 = feature_extraction.text.TfidfVectorizer(max_features=5000)\n# X_tfidf = tfidf_vectorizer2.fit_transform(X['text_preproc']);\n# X_test_tfidf = tfidf_vectorizer2.transform(X_test['text_preproc']);","metadata":{"execution":{"iopub.status.busy":"2023-08-05T20:01:03.670497Z","iopub.execute_input":"2023-08-05T20:01:03.671096Z","iopub.status.idle":"2023-08-05T20:01:03.679034Z","shell.execute_reply.started":"2023-08-05T20:01:03.671060Z","shell.execute_reply":"2023-08-05T20:01:03.678001Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T20:01:03.680938Z","iopub.execute_input":"2023-08-05T20:01:03.681739Z","iopub.status.idle":"2023-08-05T20:01:03.689995Z","shell.execute_reply.started":"2023-08-05T20:01:03.681703Z","shell.execute_reply":"2023-08-05T20:01:03.688919Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# # Bag of words\n\n# count_vectorizer = feature_extraction.text.CountVectorizer(max_features=5000)\n# X_bow = count_vectorizer.fit_transform(X['text']);\n\n# X_train_bow = count_vectorizer.transform(X_train['text'])\n# X_test_bow = count_vectorizer.transform(X_test['text'])\n\n# # TF-IDF\n\n# tf_idf_trans = feature_extraction.text.TfidfVectorizer(max_features=5000)\n# X_tf_idf = tf_idf_trans.fit_transform(X['text'])\n\n# X_train_tf_idf = tf_idf_trans.transform(X_train)\n# X_test_tf_idf = tf_idf_trans.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T20:01:03.696478Z","iopub.execute_input":"2023-08-05T20:01:03.696777Z","iopub.status.idle":"2023-08-05T20:01:03.702096Z","shell.execute_reply.started":"2023-08-05T20:01:03.696745Z","shell.execute_reply":"2023-08-05T20:01:03.700829Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Modelling","metadata":{}},{"cell_type":"code","source":"# def cross_validate_helper(model, X, y):\n#     return pd.DataFrame(cross_validate(model, X, y, scoring=[\"f1\", \"accuracy\", \"r2\"], return_train_score=True)).agg(['mean', 'std'])","metadata":{"execution":{"iopub.status.busy":"2023-08-05T20:01:03.703828Z","iopub.execute_input":"2023-08-05T20:01:03.704217Z","iopub.status.idle":"2023-08-05T20:01:03.715848Z","shell.execute_reply.started":"2023-08-05T20:01:03.704185Z","shell.execute_reply":"2023-08-05T20:01:03.714594Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# experiments = {\"naivebayes_tfidf_preproc\":dict(model=MultinomialNB(), X=X_tfidf, y=y),\n#                \"naivebayes_bow_preproc\":dict(model=MultinomialNB(), X=X_bow, y=y),\n#                 \"naivebayes_tfidf_raw\":dict(model=MultinomialNB(), X=X_tfidf_raw, y=y),\n#                 \"naivebayes_bow_raw\":dict(model=MultinomialNB(), X=X_bow_raw, y=y),    \n# }","metadata":{"execution":{"iopub.status.busy":"2023-08-05T20:01:03.717523Z","iopub.execute_input":"2023-08-05T20:01:03.718014Z","iopub.status.idle":"2023-08-05T20:01:03.726431Z","shell.execute_reply.started":"2023-08-05T20:01:03.717977Z","shell.execute_reply":"2023-08-05T20:01:03.725265Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# pd.DataFrame([cross_validate_helper(**experiment_args).unstack().rename(experiment_name) \n#               for experiment_name, experiment_args in experiments.items()]\n#             ).sort_values(('test_f1','mean'),ascending=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T20:01:03.727764Z","iopub.execute_input":"2023-08-05T20:01:03.728281Z","iopub.status.idle":"2023-08-05T20:01:03.737272Z","shell.execute_reply.started":"2023-08-05T20:01:03.728248Z","shell.execute_reply":"2023-08-05T20:01:03.736238Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# def fit_return_metrics(X_train_input, y_train_input, X_test_input,y_test_input, model):\n#     \"\"\"Fit the model, and return train and test metrics\"\"\"\n\n#     model.fit(X_train_input, y_train_input);\n#     y_train_pred = model.predict(X_train_input)\n#     y_test_pred = model.predict(X_test_input)\n\n#     # train\n    \n#     metric_set = dict(f1=f1_score, \n#                       r2=r2_score,\n#                       accuracy = accuracy_score)\n    \n#     def metrics_dict(y_act, y_pred):\n#         return{metric : metric_func(y_act, y_pred) for metric, metric_func in metric_set.items()}\n      \n#     metrics_list = [dict(regime=\"train\", **metrics_dict(y_train_input,y_train_pred)),\n#                    dict(regime=\"test\", **metrics_dict(y_test_input, y_test_pred))\n#                    ]\n    \n#     return pd.DataFrame(metrics_list).set_index(\"regime\").unstack()","metadata":{"execution":{"iopub.status.busy":"2023-08-05T20:01:03.738783Z","iopub.execute_input":"2023-08-05T20:01:03.739481Z","iopub.status.idle":"2023-08-05T20:01:03.748696Z","shell.execute_reply.started":"2023-08-05T20:01:03.739448Z","shell.execute_reply":"2023-08-05T20:01:03.747617Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# pd.DataFrame([fit_return_metrics(X_train_bow, y_train, X_test_bow,y_test,xgboost.XGBClassifier()).rename('xgboost_bow'),\n#               fit_return_metrics(X_train_tf_idf, y_train, X_test_tf_idf,y_test,xgboost.XGBClassifier()).rename('xgboost_tfidf'),\n# #               fit_return_metrics(X_train_bow.toarray(), y_train, X_test_bow.toarray(),y_test,GaussianProcessClassifier()).rename('gaussianprocess_bow'),\n# #               fit_return_metrics(X_train_bow.toarray(), y_train, X_test_tf_idf.toarray(),y_test,GaussianProcessClassifier()).rename('gaussianprocess_tfidf'),\n# #               fit_return_metrics(X_train_bow.toarray(), y_train, X_test_bow.toarray(),y_test,MultinomialNB()).rename('naivebayes_bow'),\n# #               fit_return_metrics(X_train_bow.toarray(), y_train, X_test_tf_idf.toarray(),y_test,MultinomialNB()).rename('naivebayes_tfidf')\n#              ])\n \n ","metadata":{"execution":{"iopub.status.busy":"2023-08-05T20:01:03.750246Z","iopub.execute_input":"2023-08-05T20:01:03.750918Z","iopub.status.idle":"2023-08-05T20:01:03.763489Z","shell.execute_reply.started":"2023-08-05T20:01:03.750886Z","shell.execute_reply":"2023-08-05T20:01:03.762460Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# see this notebook for BERT implementation \n# https://www.kaggle.com/code/alexia/kerasnlp-starter-notebook-disaster-tweets","metadata":{"execution":{"iopub.status.busy":"2023-08-05T20:01:03.765147Z","iopub.execute_input":"2023-08-05T20:01:03.765912Z","iopub.status.idle":"2023-08-05T20:01:03.774012Z","shell.execute_reply.started":"2023-08-05T20:01:03.765877Z","shell.execute_reply":"2023-08-05T20:01:03.773114Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Bert","metadata":{}},{"cell_type":"markdown","source":"See these: \n- https://www.kaggle.com/code/pritishmishra/text-classification-with-distilbert-92-accuracy\n- https://huggingface.co/docs/transformers/tasks/sequence_classification\n\nGoing with Pytorch as the API seems way easier","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\nimport torch\nimport datasets\n\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n\ndef preprocess_function(examples):\n    return tokenizer(examples[\"text\"], truncation=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T20:01:03.777074Z","iopub.execute_input":"2023-08-05T20:01:03.777690Z","iopub.status.idle":"2023-08-05T20:01:05.802606Z","shell.execute_reply.started":"2023-08-05T20:01:03.777663Z","shell.execute_reply":"2023-08-05T20:01:05.797622Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c163f824ad2c4245894830a787db413a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24e6341d0a374729aa8bb01796172b6f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52b553f4423e4a488910ab1bfaa3e997"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"372b6f4ecd4b478e8c8b479be3f5c900"}},"metadata":{}}]},{"cell_type":"code","source":"train_dataset = datasets.Dataset.from_pandas(train_df[['text', 'target']].rename(columns={'target':'label'})).train_test_split(test_size=0.2)\ntrain_dataset_tokenized = train_dataset.map(preprocess_function, batched=True)\n\ntest_dataset = datasets.Dataset.from_pandas(test_df[['text']])#.train_test_split(test_size=0.2)\ntest_dataset_tokenized = test_dataset.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T20:01:05.810219Z","iopub.execute_input":"2023-08-05T20:01:05.813044Z","iopub.status.idle":"2023-08-05T20:01:07.640537Z","shell.execute_reply.started":"2023-08-05T20:01:05.813001Z","shell.execute_reply":"2023-08-05T20:01:07.639508Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0ff1ccaf4bc4fada93af2b6e4791169"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cdc14e74df7420a98526c39c1a63346"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a9c1faa9ecc436cb5703b5aa76876f1"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding\n\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)#, return_tensors=\"tf\")","metadata":{"execution":{"iopub.status.busy":"2023-08-05T20:01:07.642578Z","iopub.execute_input":"2023-08-05T20:01:07.643189Z","iopub.status.idle":"2023-08-05T20:01:07.671535Z","shell.execute_reply.started":"2023-08-05T20:01:07.643154Z","shell.execute_reply":"2023-08-05T20:01:07.670611Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n\nid2label = {0: 0, 1:1}\nlabel2id = {0: 0, 1: 1}\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T20:01:07.675212Z","iopub.execute_input":"2023-08-05T20:01:07.676821Z","iopub.status.idle":"2023-08-05T20:01:13.925043Z","shell.execute_reply.started":"2023-08-05T20:01:07.676783Z","shell.execute_reply":"2023-08-05T20:01:13.924053Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05762d93ea974aff8defd17b2beeb855"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias']\n- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"def compute_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    f1 = f1_score(labels, preds, average=\"weighted\")\n    acc = accuracy_score(labels, preds)\n    return {\"accuracy\": acc, \"f1\": f1}","metadata":{"execution":{"iopub.status.busy":"2023-08-05T20:01:13.926590Z","iopub.execute_input":"2023-08-05T20:01:13.927162Z","iopub.status.idle":"2023-08-05T20:01:13.933205Z","shell.execute_reply.started":"2023-08-05T20:01:13.927124Z","shell.execute_reply":"2023-08-05T20:01:13.932225Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"batch_size = 64\nlogging_steps = len(train_dataset_tokenized[\"train\"]) // batch_size\n\ntraining_args = TrainingArguments(\n    output_dir=\"distilbert_finetuned_natural_disaster_tweets_model\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=5,\n    weight_decay=0.01,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    push_to_hub=False,\n    # added these\n    #metrics_for_best_model='f1',\n    #greater_is_better=True,\n    eval_steps=batch_size,\n    logging_steps=batch_size,\n    report_to=\"none\"\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T20:01:35.877502Z","iopub.execute_input":"2023-08-05T20:01:35.877914Z","iopub.status.idle":"2023-08-05T20:01:35.893244Z","shell.execute_reply.started":"2023-08-05T20:01:35.877884Z","shell.execute_reply":"2023-08-05T20:01:35.892235Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset_tokenized[\"train\"],\n    eval_dataset=train_dataset_tokenized[\"test\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T20:01:39.196384Z","iopub.execute_input":"2023-08-05T20:01:39.196760Z","iopub.status.idle":"2023-08-05T20:01:45.056386Z","shell.execute_reply.started":"2023-08-05T20:01:39.196732Z","shell.execute_reply":"2023-08-05T20:01:45.055337Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-08-05T20:01:45.058639Z","iopub.execute_input":"2023-08-05T20:01:45.059006Z","iopub.status.idle":"2023-08-05T20:03:36.803146Z","shell.execute_reply.started":"2023-08-05T20:01:45.058971Z","shell.execute_reply":"2023-08-05T20:03:36.802060Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\nYou're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='240' max='240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [240/240 01:44, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.417848</td>\n      <td>0.819435</td>\n      <td>0.812393</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.471800</td>\n      <td>0.382209</td>\n      <td>0.843729</td>\n      <td>0.840691</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.351900</td>\n      <td>0.382427</td>\n      <td>0.850295</td>\n      <td>0.848127</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.310400</td>\n      <td>0.390988</td>\n      <td>0.845699</td>\n      <td>0.844655</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.310400</td>\n      <td>0.397481</td>\n      <td>0.839133</td>\n      <td>0.838409</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=240, training_loss=0.35895636479059856, metrics={'train_runtime': 111.3853, 'train_samples_per_second': 273.375, 'train_steps_per_second': 2.155, 'total_flos': 506432696626632.0, 'train_loss': 0.35895636479059856, 'epoch': 5.0})"},"metadata":{}}]},{"cell_type":"code","source":"preds_output = trainer.predict(train_dataset_tokenized[\"test\"])\n\ny_preds = np.argmax(preds_output.predictions, axis=1)\n\npreds_output.metrics","metadata":{"execution":{"iopub.status.busy":"2023-08-05T20:03:36.804701Z","iopub.execute_input":"2023-08-05T20:03:36.805141Z","iopub.status.idle":"2023-08-05T20:03:38.656860Z","shell.execute_reply.started":"2023-08-05T20:03:36.805106Z","shell.execute_reply":"2023-08-05T20:03:38.655545Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"{'test_loss': 0.38220903277397156,\n 'test_accuracy': 0.8437294812869337,\n 'test_f1': 0.8406914260093497,\n 'test_runtime': 1.8372,\n 'test_samples_per_second': 828.996,\n 'test_steps_per_second': 6.532}"},"metadata":{}}]},{"cell_type":"markdown","source":"# Submit best model","metadata":{}},{"cell_type":"code","source":"# best_model = MultinomialNB()\n\n# best_model.fit(X_bow_raw, y)\n\n# y_pred_test  = best_model.predict(X_test_bow_raw)\n\npreds_output = trainer.predict(test_dataset_tokenized)\n\ny_pred_test = np.argmax(preds_output.predictions, axis=1)\n\npreds_output.metrics","metadata":{"execution":{"iopub.status.busy":"2023-08-05T20:04:52.821763Z","iopub.execute_input":"2023-08-05T20:04:52.822146Z","iopub.status.idle":"2023-08-05T20:04:56.740355Z","shell.execute_reply.started":"2023-08-05T20:04:52.822115Z","shell.execute_reply":"2023-08-05T20:04:56.739369Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"{'test_runtime': 3.9,\n 'test_samples_per_second': 836.676,\n 'test_steps_per_second': 6.667}"},"metadata":{}}]},{"cell_type":"code","source":"# Create a submission dataframe\nsubmission = pd.DataFrame({'id': test_df['id'], 'target': y_pred_test})\n\n# Write the submission dataframe to a CSV file\nsubmission.to_csv('submission.csv', index=False)\n\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-05T20:04:56.745283Z","iopub.execute_input":"2023-08-05T20:04:56.747945Z","iopub.status.idle":"2023-08-05T20:04:56.784817Z","shell.execute_reply.started":"2023-08-05T20:04:56.747906Z","shell.execute_reply":"2023-08-05T20:04:56.783856Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"   id  target\n0   0       0\n1   2       1\n2   3       1\n3   9       1\n4  11       1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}