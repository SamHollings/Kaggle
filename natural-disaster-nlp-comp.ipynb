{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ToDo:\n- preprocess text - lemmatization, remove stop words etc. \n- utlise preprocessed text\n- Try DistilBert https://www.kaggle.com/code/alexia/kerasnlp-starter-notebook-disaster-tweets\n- sklearn pipelines\n- cross validation\n","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn import feature_extraction, linear_model, model_selection, preprocessing\nfrom sklearn.model_selection import train_test_split, cross_validate\nfrom sklearn.metrics import f1_score, r2_score, accuracy_score\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.pipeline import Pipeline\nimport xgboost\nimport spacy","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:59:31.735642Z","iopub.execute_input":"2023-08-02T13:59:31.736122Z","iopub.status.idle":"2023-08-02T13:59:31.743770Z","shell.execute_reply.started":"2023-08-02T13:59:31.736088Z","shell.execute_reply":"2023-08-02T13:59:31.742678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nlp = spacy.load('en_core_web_sm')","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:53:22.521579Z","iopub.execute_input":"2023-08-02T13:53:22.522255Z","iopub.status.idle":"2023-08-02T13:53:23.885903Z","shell.execute_reply.started":"2023-08-02T13:53:22.522225Z","shell.execute_reply":"2023-08-02T13:53:23.884805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:53:23.887596Z","iopub.execute_input":"2023-08-02T13:53:23.888050Z","iopub.status.idle":"2023-08-02T13:53:23.972963Z","shell.execute_reply.started":"2023-08-02T13:53:23.888011Z","shell.execute_reply":"2023-08-02T13:53:23.971758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preproc","metadata":{}},{"cell_type":"code","source":"def lemmatize_remove_stop(doc):\n    return (\" \".join([token.lemma_ for token in nlp(doc) if not token.is_stop])).strip().lower()","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:53:23.976323Z","iopub.execute_input":"2023-08-02T13:53:23.976800Z","iopub.status.idle":"2023-08-02T13:53:23.982757Z","shell.execute_reply.started":"2023-08-02T13:53:23.976759Z","shell.execute_reply":"2023-08-02T13:53:23.981354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['text_preproc'] = train_df['text'].apply(lemmatize_remove_stop)\ntest_df['text_preproc'] = test_df['text'].apply(lemmatize_remove_stop)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:53:23.984522Z","iopub.execute_input":"2023-08-02T13:53:23.985273Z","iopub.status.idle":"2023-08-02T13:55:11.042526Z","shell.execute_reply.started":"2023-08-02T13:53:23.985234Z","shell.execute_reply":"2023-08-02T13:55:11.041469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train_df.set_index('id')\ny = train_df.set_index('id')['target']\n\nX_test = test_df.set_index('id')","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:55:11.043949Z","iopub.execute_input":"2023-08-02T13:55:11.044556Z","iopub.status.idle":"2023-08-02T13:55:11.057738Z","shell.execute_reply.started":"2023-08-02T13:55:11.044504Z","shell.execute_reply":"2023-08-02T13:55:11.056530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_vectorizer = feature_extraction.text.CountVectorizer(max_features=5000)\nX_bow_raw = count_vectorizer.fit_transform(X['text'])\nX_test_bow_raw = count_vectorizer.transform(X_test['text'])\n\ncount_vectorizer2 = feature_extraction.text.CountVectorizer(max_features=5000)\nX_bow = count_vectorizer2.fit_transform(X['text_preproc']);\nX_test_bow = count_vectorizer2.transform(X_test['text_preproc']);","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:55:11.058765Z","iopub.execute_input":"2023-08-02T13:55:11.059070Z","iopub.status.idle":"2023-08-02T13:55:11.684751Z","shell.execute_reply.started":"2023-08-02T13:55:11.059043Z","shell.execute_reply":"2023-08-02T13:55:11.683599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfidf_vectorizer = feature_extraction.text.TfidfVectorizer(max_features=5000)\nX_tfidf_raw = tfidf_vectorizer.fit_transform(X['text'])\nX_test_tfidf_raw = tfidf_vectorizer.transform(X_test['text'])\n\ntfidf_vectorizer2 = feature_extraction.text.TfidfVectorizer(max_features=5000)\nX_tfidf = tfidf_vectorizer2.fit_transform(X['text_preproc']);\nX_test_tfidf = tfidf_vectorizer2.transform(X_test['text_preproc']);","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:55:11.686306Z","iopub.execute_input":"2023-08-02T13:55:11.686649Z","iopub.status.idle":"2023-08-02T13:55:12.321419Z","shell.execute_reply.started":"2023-08-02T13:55:11.686621Z","shell.execute_reply":"2023-08-02T13:55:12.320202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:33:48.419999Z","iopub.status.idle":"2023-08-02T13:33:48.420442Z","shell.execute_reply.started":"2023-08-02T13:33:48.420239Z","shell.execute_reply":"2023-08-02T13:33:48.420260Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Bag of words\n\n# count_vectorizer = feature_extraction.text.CountVectorizer(max_features=5000)\n# X_bow = count_vectorizer.fit_transform(X['text']);\n\n# X_train_bow = count_vectorizer.transform(X_train['text'])\n# X_test_bow = count_vectorizer.transform(X_test['text'])\n\n# # TF-IDF\n\n# tf_idf_trans = feature_extraction.text.TfidfVectorizer(max_features=5000)\n# X_tf_idf = tf_idf_trans.fit_transform(X['text'])\n\n# X_train_tf_idf = tf_idf_trans.transform(X_train)\n# X_test_tf_idf = tf_idf_trans.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:33:48.422479Z","iopub.status.idle":"2023-08-02T13:33:48.422899Z","shell.execute_reply.started":"2023-08-02T13:33:48.422700Z","shell.execute_reply":"2023-08-02T13:33:48.422720Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modelling","metadata":{}},{"cell_type":"code","source":"pd.DataFrame(cross_validate(MultinomialNB(), X_tfidf, y, scoring=[\"f1\", \"accuracy\", \"r2\"], return_train_score=True)).agg(['mean', 'std'])","metadata":{"execution":{"iopub.status.busy":"2023-08-02T14:09:05.438990Z","iopub.execute_input":"2023-08-02T14:09:05.439554Z","iopub.status.idle":"2023-08-02T14:09:05.567402Z","shell.execute_reply.started":"2023-08-02T14:09:05.439498Z","shell.execute_reply":"2023-08-02T14:09:05.566162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit_return_metrics(X_train_input, y_train_input, X_test_input,y_test_input, model):\n    \"\"\"Fit the model, and return train and test metrics\"\"\"\n\n    model.fit(X_train_input, y_train_input);\n    y_train_pred = model.predict(X_train_input)\n    y_test_pred = model.predict(X_test_input)\n\n    # train\n    \n    metric_set = dict(f1=f1_score, \n                      r2=r2_score,\n                      accuracy = accuracy_score)\n    \n    def metrics_dict(y_act, y_pred):\n        return{metric : metric_func(y_act, y_pred) for metric, metric_func in metric_set.items()}\n      \n    metrics_list = [dict(regime=\"train\", **metrics_dict(y_train_input,y_train_pred)),\n                   dict(regime=\"test\", **metrics_dict(y_test_input, y_test_pred))\n                   ]\n    \n    return pd.DataFrame(metrics_list).set_index(\"regime\").unstack()","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:33:48.425709Z","iopub.status.idle":"2023-08-02T13:33:48.426787Z","shell.execute_reply.started":"2023-08-02T13:33:48.426567Z","shell.execute_reply":"2023-08-02T13:33:48.426590Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame([fit_return_metrics(X_train_bow, y_train, X_test_bow,y_test,xgboost.XGBClassifier()).rename('xgboost_bow'),\n              fit_return_metrics(X_train_tf_idf, y_train, X_test_tf_idf,y_test,xgboost.XGBClassifier()).rename('xgboost_tfidf'),\n#               fit_return_metrics(X_train_bow.toarray(), y_train, X_test_bow.toarray(),y_test,GaussianProcessClassifier()).rename('gaussianprocess_bow'),\n#               fit_return_metrics(X_train_bow.toarray(), y_train, X_test_tf_idf.toarray(),y_test,GaussianProcessClassifier()).rename('gaussianprocess_tfidf'),\n#               fit_return_metrics(X_train_bow.toarray(), y_train, X_test_bow.toarray(),y_test,MultinomialNB()).rename('naivebayes_bow'),\n#               fit_return_metrics(X_train_bow.toarray(), y_train, X_test_tf_idf.toarray(),y_test,MultinomialNB()).rename('naivebayes_tfidf')\n             ])\n \n ","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:33:48.427885Z","iopub.status.idle":"2023-08-02T13:33:48.429019Z","shell.execute_reply.started":"2023-08-02T13:33:48.428805Z","shell.execute_reply":"2023-08-02T13:33:48.428828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# see this notebook for BERT implementation \n# https://www.kaggle.com/code/alexia/kerasnlp-starter-notebook-disaster-tweets","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:33:48.430525Z","iopub.status.idle":"2023-08-02T13:33:48.430957Z","shell.execute_reply.started":"2023-08-02T13:33:48.430756Z","shell.execute_reply":"2023-08-02T13:33:48.430776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_model = xgboost.XGBClassifier()\n\nbest_model.fit(X_bow, y)\n\nX_test_bow = count_vectorizer.transform(test_df['text'])\n\ny_pred_test  = best_model.predict(X_test_bow)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:33:48.433023Z","iopub.status.idle":"2023-08-02T13:33:48.433954Z","shell.execute_reply.started":"2023-08-02T13:33:48.433671Z","shell.execute_reply":"2023-08-02T13:33:48.433699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a submission dataframe\nsubmission = pd.DataFrame({'id': test_df['id'], 'target': y_pred_test})\n\n# Write the submission dataframe to a CSV file\nsubmission.to_csv('submission.csv', index=False)\n\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:33:48.435245Z","iopub.status.idle":"2023-08-02T13:33:48.435732Z","shell.execute_reply.started":"2023-08-02T13:33:48.435460Z","shell.execute_reply":"2023-08-02T13:33:48.435486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}